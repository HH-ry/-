# 吃瓜打卡(2023/12/12)

## “南瓜书” (“pumpkin_book.pdf”, p. 1)

### “第 1 章 绪论” (“pumpkin_book.pdf”, p. 14)



- ““算法”是指从数据中学得“模型”的具 体方法，例如后续章节中将会讲述的线性回归、对数几率回归、决策树等” (“pumpkin_book.pdf”, p. 14)

- ““算法”产出的结果称为“模型”， 通常是具体的函数或者可抽象地看作为函数，例如一元线性回归算法产出的模型即为形如 f (x) = wx + b 的一元一次函数。” (“pumpkin_book.pdf”, p. 14)

- “样本：也称为“示例”，是关于一个事件或对象的描述。” (“pumpkin_book.pdf”, p. 14)

- “线性代数中的向量就很适合，因为任何事物都可以由若干“特 征”（或称为“属性”）唯一刻画出来，而向量的各个维度即可用来描述各个特征” (“pumpkin_book.pdf”, p. 14)
- “样本空间：也称为“输入空间”或“属性空间”。” (“pumpkin_book.pdf”, p. 14)
- “表示样本的特征向量所在 的空间为样本空间，通常用花式大写的 X 表示。 数据集：数据集通常用集合来表示，令集合 D =” (“pumpkin_book.pdf”, p. 14)

- “数据集：数据集通常用集合来表示” (“pumpkin_book.pdf”, p. 14)

  - “令集合 D = {x1, x2, ..., xm} 表示包含 m 个样本的数据集，一般 同一份数据集中的每个样本都含有相同个数的特征，假设此数据集中的每个样本都含有 d 个特征，则第 i 个样本的数学表示为 d 维向量：xi = (xi1; xi2; ...; xid)，其中 xij 表示样本 xi 在第 j 个属性上的取值。” (“pumpkin_book.pdf”, p. 14)


- “模型：机器学习的一般流程如下：首先收集若干样本（假设此时有 100 个），然后将其分为训练样本 （80 个）和测试样本（20 个），其中 80 个训练样本构成的集合称为“训练集”，20 个测试样本构成的集合 称为“测试集”，接着选用某个机器学习算法，让其在训练集上进行“学习”（或称为“训练”），然后产出 得到“模型”（或称为“学习器”），最后用测试集来测试模型的效果。” (“pumpkin_book.pdf”, p. 14)
  - “当我们应用某个机 器学习算法来学习时，产出得到的模型便是该算法所找到的它自己认为的规律，由于该规律通常并不一定” (“pumpkin_book.pdf”, p. 14)

- “就是所谓的真相，所以也将其称为“假设”。” (“pumpkin_book.pdf”, p. 15)

- “通常机器学习算法都有可配置的参数，同一个机器学习算法， 使用不同的参数配置或者不同的训练集，训练得到的模型通常都不同。” (“pumpkin_book.pdf”, p. 15)

- “标记：上文提到机器学习的本质就是在学习样本在某个方面的表现是否存在潜在的规律，我们称该方 面的信息为“标记”” (“pumpkin_book.pdf”, p. 15)
  - “一般第 i 个样本的 标记的数学表示为 yi，标记所在的空间称为“标记空间”或“输出空间”，数学表示为花式大写的 Y。标 记通常也看作为样本的一部分，因此，一个完整的样本通常表示为 (x, y)。” (“pumpkin_book.pdf”, p. 15)
- “根据标记的取值类型不同，可将机器学习任务分为以下两类：” (“pumpkin_book.pdf”, p. 15)

  - “• 当标记取值为离散型时，称此类任务为“分类”，” (“pumpkin_book.pdf”, p. 15)

    - “当分类的类别只有两个时，称此类任务为“二分类”，通常称其中一个为“正类”，另 一个为“反类”或“负类”；当分类的类别超过两个时，称此类任务为“多分类”。” (“pumpkin_book.pdf”, p. 15)

  - “• 当标记取值为连续型时，称此类任务为“回归”” (“pumpkin_book.pdf”, p. 15)

    - “由于是连续型，因此标记的所有可能取值无法直接罗列，通常只有取值范围，回归任务的标记取 值范围通常是整个实数域 R，即 Y = R。” (“pumpkin_book.pdf”, p. 15)
  - “无论是分类还是回归，机器学习算法最终学得的模型都可以抽象地看作为以样本 x 为自变量，标记 y 为因变量的函数 y = f (x)，即一个从输入空间 X 到输出空间 Y 的映射。” (“pumpkin_book.pdf”, p. 15)

- “根据是否有用到标记信息，可将机器学习任务分为以下两类： • 在模型训练阶段有用到标记信息时，称此类任务为“监督学习”，例如第 3 章的线性模型； • 在模型训练阶段没用到标记信息时，称此类任务为“无监督学习”，例如第 9 章的聚类。” (“pumpkin_book.pdf”, p. 15)

- “泛化：由于机器学习的目标是根据已知来对未知做出尽可能准确的判断，因此对未知事物判断的准确 与否才是衡量一个模型好坏的关键，我们称此为“泛化”能力” (“pumpkin_book.pdf”, p. 15)

- “导致此现象最直接的原因是算法的不同，但是算法通常 是有限的，可穷举的，尤其是在特定任务场景下可使用的算法更是有限，因此，数据便是导致此现象的另 一重要原因，这也就是机器学习领域常说的“数据决定模型的上限，而算法则是让模型无限逼近上限”” (“pumpkin_book.pdf”, p. 15)

- “分布：此处的“分布”指的是概率论中的概率分布，” (“pumpkin_book.pdf”, p. 16)

  - “通常假设样本空间服从一个未知“分布”D，而 我们收集到的每个样本都是独立地从该分布中采样得到，即“独立同分布”。通常收集到的样本越多，越 能从样本中反推出 D 的信息，即越接近真相。此假设属于机器学习中的经典假设，” (“pumpkin_book.pdf”, p. 16)

- “可以有多个假设空间，且在不同的假设空间中都有可能学得能够拟合训练集的模型，我们将所 有能够拟合训练集的模型构成的集合称为“版本空间”。” (“pumpkin_book.pdf”, p. 16)

- “所以不同的机器学习算法有不同的偏好，我们称为 “归纳偏好”” (“pumpkin_book.pdf”, p. 16)

- “著名的“奥卡姆剃 刀”原则认为“若有多个假设与观察一致，则选最简单的那个”，” (“pumpkin_book.pdf”, p. 16)“而最常用的方法则是基于模型在测试 集上的表现来评判模型之间的优劣” (“pumpkin_book.pdf”, p. 16)

- “机器学习算法之间没有绝对的优劣之分，只有是否适合当前待解决的问题之分，” (“pumpkin_book.pdf”, p. 17)

- “需要注意的是，在这里我们假设真实的目标函数 f 服从均匀分布，但是实际情形并非如此，” (“pumpkin_book.pdf”, p. 17)


### “第 2 章 模型评估与选择” (“pumpkin_book.pdf”, p. 18)

- “错误率：E = a m ，其中 m 为样本个数，a 为分类错误样本个数。” (“pumpkin_book.pdf”, p. 18)

- “精度：精度 =1-错误率。” (“pumpkin_book.pdf”, p. 18)

- “误差：学习器的实际预测输出与样本的真实输出之间的差异。” (“pumpkin_book.pdf”, p. 18)

- “经验误差：学习器在训练集上的误差，又称为“训练误差”。” (“pumpkin_book.pdf”, p. 18)

- “泛化误差：学习器在新样本上的误差。” (“pumpkin_book.pdf”, p. 18)

- “错误率和精度很容易理解，而且很明显是针对分类问题的。误差的概念更适用于回归问题，但是，根 据“西瓜书”第 12 章的式 (12.1) 和式 (12.2) 的定义可以看出，在分类问题中也会使用误差的概念” (“pumpkin_book.pdf”, p. 18)

- “过拟合是由于模型的学习能力相对于数据来说过于强大，反过来说，欠拟合是因为模型的学习能力相 对于数据来说过于低下” (“pumpkin_book.pdf”, p. 18)

- “3 种模型评估方法：留出法、交叉验证法、自助法” (“pumpkin_book.pdf”, p. 18)

  - “交叉验证法的常用方式。” (“pumpkin_book.pdf”, p. 18)

    - “对比同一算法的不同参数配置之间的效果：” (“pumpkin_book.pdf”, p. 18)

    - “对比不同算法之间的效果：” (“pumpkin_book.pdf”, p. 19)

  - “交叉验证法本质上是在进行多次留出法，且每次都换不同的子集做测试集， 最终让所有样本均至少做 1 次测试样本。” (“pumpkin_book.pdf”, p. 19)

- “算法参数是指算法本身的一些参数（也称超参数），” (“pumpkin_book.pdf”, p. 19)

- “算法配置好相应参数后进行训练，训练结束会得到一个模型，例如支 持向量机最终会得到 w 和 b 的具体数值（此处不考虑核函数），这就是模型参数，模型配置好相应模型参 数后即可对新样本做预测。” (“pumpkin_book.pdf”, p. 19)

- “但是交叉验证法操作起来较为复杂，实际中更 多采用的是：先用留出法将数据集划分出训练集和测试集，然后再对训练集采用留出法划分出训练集和新 的测试集，称新的测试集为验证集，接着基于验证集的测试结果来调参选出最优参数配置方案，最后将验 证集合并进训练集（训练集数据量够的话也可不合并），用选出的最优参数配置在合并后的训练集上重新 训练，再用测试集来评估训练得到的模型的性能。” (“pumpkin_book.pdf”, p. 19)

- “本节性能度量指标较多，但是一般常用的只有错误率、精度、查准率、查全率、F1、ROC 和 AUC。” (“pumpkin_book.pdf”, p. 19)

- “式 (2.2)、式 (2.4) 和式 (2.5) 假 设了数据分布为均匀分布，即每个样本出现的概率相同，而式 (2.3)、式 (2.6) 和式 (2.7) 则为更一般的表 达式” (“pumpkin_book.pdf”, p. 19)

- “在无特别说明的情况下，2.3 节所有公式中的“样例集 D”均默认为非训练集（测试集、验 证集或其他未用于训练的样例集）。” (“pumpkin_book.pdf”, p. 19)

- “查准率 P ：被学习器预测为正例的样例中有多大比例是真正例。” (“pumpkin_book.pdf”, p. 19)

- “查全率 R：所有正例当中有多大比例被学习器预测为正例。” (“pumpkin_book.pdf”, p. 19)

- “P-R 曲线的画法与 ROC 曲线的画法类似，也是通过依次改变模型阈值，然后计算出查准率和查全率 并画出相应坐标点” (“pumpkin_book.pdf”, p. 19)
